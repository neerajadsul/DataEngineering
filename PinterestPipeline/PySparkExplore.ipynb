{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f660c-a37f-4132-8619-298017e77ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from user_posting_emulation import AWSDBConnector\n",
    "from sqlalchemy import inspect, text\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de266d-8c6d-459a-bb9f-b9520ee0b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_data(topic_table, num_rows=2000):\n",
    "    dbc = AWSDBConnector().create_db_connector()\n",
    "    table_names = inspect(dbc).get_table_names()\n",
    "    if topic_table not in table_names:\n",
    "        raise ValueError(f'Given table `{topic_table}` not found in the database.')\n",
    "\n",
    "    with dbc.connect() as conn:\n",
    "        query = text(f'SELECT * FROM {topic_table} LIMIT {num_rows};')\n",
    "        result = conn.execute(query)\n",
    "\n",
    "    data = []\n",
    "    for row in result:\n",
    "        data.append(dict(row._mapping))\n",
    "    \n",
    "    return data\n",
    "\n",
    "df_pin = pd.json_normalize(get_topic_data('pinterest_data', num_rows=11154))\n",
    "# df_geo = pd.json_normalize(get_topic_data('geolocation_data', num_rows=11154))\n",
    "# df_user = pd.json_normalize(get_topic_data('user_data', num_rows=11154))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874f08c-ef2a-425b-a931-090a42c302c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pyspark\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.pandas as psd\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "os.environ[\"SPARK_LOCAL_IP\"] = \"192.168.1.211\"\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47dab15-e400-4083-8b30-d8f71fe5f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = (\n",
    "    pyspark.SparkConf()\n",
    "    # Setting the master to run locally and with the maximum amount of cpu coresfor multiprocessing.\n",
    "    .setMaster(f\"local[{multiprocessing.cpu_count()//2}]\")\n",
    "    # Setting application name\n",
    "    .setAppName(\"S3ToSparkConnection\")\n",
    "    # Setting config value via string\n",
    "    # .set(\"spark.eventLog.enabled\", False)\n",
    "    # Setting environment variables for executors to use\n",
    "    # .setExecutorEnv(pairs=[(\"VAR3\", \"value3\"), (\"VAR4\", \"value4\")])\n",
    "    # Setting memory if this setting was not set previously\n",
    "    .setIfMissing(\"spark.executor.memory\", \"2g\")\n",
    "    .setMaster('local[*]')\n",
    ")\n",
    "\n",
    "# Getting a single variable\n",
    "print(cfg.get(\"spark.executor.memory\"))\n",
    "# Listing all of them in string readable format\n",
    "print(cfg.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c82a9-24ff-4b35-8d79-bb9e8138710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = pyspark.sql.SparkSession.builder.config(conf=cfg).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7199fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = session.sparkContext\n",
    "ss = session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0312f-e41a-4c1a-997d-ec9ce12b4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pin_dfs = ss.createDataFrame(df_pin)\n",
    "pin_dfs = psd.DataFrame(df_pin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece4869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pin_dfs.show(5)\n",
    "# pin_dfs.show(1, vertical=True)\n",
    "# pin_dfs.printSchema()\n",
    "# pin_dfs.select('*').describe().collect()\n",
    "# pin_dfs.tail(5)\n",
    "# pin_dfs.take(5)\n",
    "# pin_dfs.select('title').show()\n",
    "pin_dfs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d36cb-f7c9-4d60-a73f-5203bb3720b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo_dfs = psd.DataFrame(df_geo)\n",
    "# user_dfs = psd.DataFrame(df_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b9a9fd-5de7-486d-81f6-80f4e32fd985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pin_dfs = pin_dfs.replace(['', 'N/A', 'n/a', 'none', 'None'], None)\n",
    "len(pin_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0cef86-1448-44f8-9103-e6c86ff82d23",
   "metadata": {},
   "source": [
    "## Clean Pin Spark DataFrame\n",
    "\n",
    "Replace empty entries and entries with no relevant data in each column with `Nones` \\\n",
    "Perform the necessary transformations on the `follower_count` to ensure every entry is a number. \\\n",
    "Make sure the data type of this column is an `int`. \\\n",
    "Ensure that each column containing numeric data has a numeric data type \\\n",
    "Clean the data in the `save_location` column to include only the save location path \\\n",
    "Rename the `index` column to `ind`. \\\n",
    "Reorder the `DataFrame` columns to have the following column order: \\\n",
    "    `ind` \\\n",
    "    `unique_id` \\\n",
    "    `title` \\\n",
    "    `description` \\\n",
    "    `follower_count` \\\n",
    "    `poster_name` \\\n",
    "    `tag_list` \\\n",
    "    `is_image_or_video` \\\n",
    "    `image_src` \\\n",
    "    `save_location` \\\n",
    "    `category`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d63c53-3519-4fbb-9390-71fba30e09a0",
   "metadata": {},
   "source": [
    "### Make sure unique ids are correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca6b31-7b09-4ce6-b863-9c6c9b593b6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uuid_regex = r'[a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12}'\n",
    "pin_dfs = pin_dfs[pin_dfs['unique_id'].str.match(uuid_regex)]\n",
    "len(pin_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352156ac-4e9d-4649-a762-5d2fa6c9591b",
   "metadata": {},
   "source": [
    "### Cleanup and transform `follower_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66753f05-9b83-4c73-8060-c33bcb5d5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "follower_regex = r'[0-9]{1,}[kM]?'\n",
    "pin_dfs = pin_dfs[pin_dfs['follower_count'].str.match(follower_regex)]\n",
    "len(pin_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db106f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_followers_count(x) -> np.int64:\n",
    "    muliplier = 1\n",
    "    if x.endswith('k'):\n",
    "        return 1000 * int(x[:-1])\n",
    "    elif x.endswith('M'):\n",
    "        return 1000000 * int(x[:-1])\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "pin_dfs['follower_count'] = pin_dfs['follower_count'].apply(transform_followers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed490a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_dfs.rename(columns={'index': 'ind'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f65239",
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_dfs['save_location'] = pin_dfs['save_location'].str.replace('Local save in ', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_dfs = pin_dfs[['ind', 'unique_id', 'title', 'description', 'follower_count', 'poster_name',\n",
    "                   'tag_list', 'is_image_or_video', 'image_src', 'save_location', 'category']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
