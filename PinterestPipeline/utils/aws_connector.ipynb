{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20874560-d77d-49a6-bede-20ab501e7a63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "class S3Connector:\n",
    "    \"\"\"Utility to mount and unmount S3 bucket with given credentials.\"\"\"\n",
    "    \n",
    "    def __init__(self, bucket_name, mount_name, credential_file):\n",
    "        self.is_mounted = False\n",
    "        self.bucket_name = bucket_name\n",
    "        self.mount_name = mount_name\n",
    "        creds = get_aws_credentials(credential_file)\n",
    "        self.source_url = f\"s3n://{creds[0]}:{creds[1]}@{self.bucket_name}\"\n",
    "\n",
    "    def mount(self):\n",
    "        \"\"\"Mount the S3 Bucket from DBFS\"\"\"\n",
    "        mount_points = (mount.mountPoint for mount in dbutils.fs.mounts())\n",
    "        if any(self.mount_name in mount for mount in mount_points):\n",
    "            self.is_mounted = True\n",
    "            print(f'{self.bucket_name} is already mounted.')\n",
    "            return\n",
    "\n",
    "        # When bucket is not already mounted and mounting is successful\n",
    "        if not self.is_mounted and dbutils.fs.mount(self.source_url, self.mount_name):\n",
    "            self.is_mounted = True\n",
    "        else:\n",
    "            raise Exception('Unable to mount the S3 Bucket')\n",
    "\n",
    "    def unmount(self):\n",
    "        \"\"\"Unmount the S3 Bucket from DBFS\"\"\"\n",
    "        if self.is_mounted and dbutils.fs.unmount(self.mount_name):\n",
    "            self.is_mounted = False\n",
    "        else:\n",
    "            raise Exception('Unable to unmount.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d9fd9a5-b51d-4cb2-b305-e08404ded431",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_aws_credentials(credentials, file_type='csv', header=True, sep=','):\n",
    "    \"\"\"Return the credentials to connect to S3 Bucket\n",
    "    \n",
    "    credentials: filename containing the AWS credentials\n",
    "    file_type: specify file type, default 'csv'\n",
    "    header: True indicates the file has first row as the header, else False\n",
    "    sep: delimiter for the file, default comma ','\n",
    "    \"\"\"\n",
    "    # Read the CSV file to spark dataframe\n",
    "    # old method not used anymore\n",
    "    # aws_keys_df = spark.read.format(file_type)\\\n",
    "    # .option(\"header\", header)\\\n",
    "    # .option(\"sep\", sep)\\\n",
    "    # .load(f\"/FileStore/tables/{credentials}\")\n",
    "\n",
    "    # Define the path to the Delta table\n",
    "    delta_table_path = \"dbfs:/user/hive/warehouse/authentication_credentials\"\n",
    "\n",
    "    # Read the Delta table to a Spark DataFrame\n",
    "    aws_keys_df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "    \n",
    "    # Get the AWS access key and secret key from the spark dataframe \n",
    "    ACCESS_KEY = aws_keys_df.select('Access key ID').collect()[0]['Access key ID'] \n",
    "    SECRET_KEY = aws_keys_df.select('Secret access key').collect()[0]['Secret access key'] # Encode the secrete key \n",
    "    ENCODED_SECRET_KEY = urllib.parse.quote(string=SECRET_KEY, safe=\"\")\n",
    "    return ACCESS_KEY, ENCODED_SECRET_KEY, SECRET_KEY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff580702-3773-4f11-8578-21a81e07f56a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_aws_connector():\n",
    "    # creds = get_aws_credentials('authentication_credentials.csv')\n",
    "    s3_conn = S3Connector('user-0a1d8948160f-bucket', '/mnt/pin_pipe', 'authentication_credentials.csv')\n",
    "    assert not s3_conn.is_mounted\n",
    "    s3_conn.mount()\n",
    "    assert s3_conn.is_mounted\n",
    "    s3_conn.unmount()\n",
    "    assert not s3_conn.is_mounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc657d02-5dca-4cb2-99db-bf6fbfd6e252",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">/mnt/pin_pipe has been unmounted.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">/mnt/pin_pipe has been unmounted.\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_aws_connector()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "aws_connector",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
